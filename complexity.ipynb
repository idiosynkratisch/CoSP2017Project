{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from swda_time import CorpusReader\n",
    "from random import randrange\n",
    "import complexity\n",
    "from nltk.tree import Tree\n",
    "import numpy as np\n",
    "\n",
    "corpus = CorpusReader('swda', 'swda/swda-metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "utterance 527"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (CC Or)\n",
      "  (NP-SBJ (NNS people))\n",
      "  (VP\n",
      "    (VBP send)\n",
      "    (NP (PRP you))\n",
      "    (ADVP-DIR (RB there))\n",
      "    (PP (IN as) (NP (DT a) (JJ last) (NN resort))))\n",
      "  (. .)\n",
      "  (-DFL- E_S))\n",
      "Length: 10\n",
      "Depth: 6\n",
      "Width: 1.55555555556\n",
      "Lu's measures:\n",
      "(ROOT (S (CC Or) (NP (NNS people)) (VP (VBP send) (NP (PRP you)) (ADVP (RB there)) (PP (IN as) (NP (DT a) (JJ last) (NN resort)))) (. .) (-DFL- E_S)))\n",
      "S|SINV|SQ [> ROOT <, (VP <# VB) | <# MD|VBZ|VBP|VBD | < (VP [<# MD|VBP|VBZ|VBD | < CC < (VP <# MD|VBP|VBZ|VBD)])] (S (CC Or) (NP (NNS people)) (VP (VBP send) (NP (PRP you)) (ADVP (RB there)) (PP (IN as) (NP (DT a) (JJ last) (NN resort)))) (. .) (-DFL- E_S))\n",
      "S|SBARQ|SINV|SQ > ROOT | [$-- S|SBARQ|SINV|SQ !>> SBAR|VP] (S (CC Or) (NP (NNS people)) (VP (VBP send) (NP (PRP you)) (ADVP (RB there)) (PP (IN as) (NP (DT a) (JJ last) (NN resort)))) (. .) (-DFL- E_S))\n",
      "ROOT\n",
      "{'S < (VP <# VBG|TO) $+ VP': 0, 'S|SBARQ|SINV|SQ [> ROOT | [$-- S|SBARQ|SINV|SQ !>> SBAR|VP]] << (SBAR < (S|SINV|SQ [> ROOT <, (VP <# VB) | <# MD|VBZ|VBP|VBD | < (VP [<# MD|VBP|VBZ|VBD | < CC < (VP <# MD|VBP|VBZ|VBD)])]))': 0, 'SBAR < (S|SINV|SQ [> ROOT <, (VP <# VB) | <# MD|VBZ|VBP|VBD | < (VP [<# MD|VBP|VBZ|VBD | < CC < (VP <# MD|VBP|VBZ|VBD)])])': 0, 'VP > S|SINV|SQ': 0, 'ADJP|ADVP|NP|VP < CC': 0, 'NP !> NP [<< JJ|POS|PP|S|VBG | << (NP $++ NP !$+ CC)]': 0, 'SBAR [<# WHNP | <# (IN < That|that|For|for) | <, S] & [$+ VP | > VP]': 0, 'MD|VBZ|VBP|VBD > (SQ !< VP)': 0, 'ROOT': 1.0}\n",
      "VP > S|SINV|SQ\n",
      "{'S < (VP <# VBG|TO) $+ VP': 0, 'S|SBARQ|SINV|SQ [> ROOT | [$-- S|SBARQ|SINV|SQ !>> SBAR|VP]] << (SBAR < (S|SINV|SQ [> ROOT <, (VP <# VB) | <# MD|VBZ|VBP|VBD | < (VP [<# MD|VBP|VBZ|VBD | < CC < (VP <# MD|VBP|VBZ|VBD)])]))': 0, 'SBAR < (S|SINV|SQ [> ROOT <, (VP <# VB) | <# MD|VBZ|VBP|VBD | < (VP [<# MD|VBP|VBZ|VBD | < CC < (VP <# MD|VBP|VBZ|VBD)])])': 0, 'VP > S|SINV|SQ': 1.0, 'ADJP|ADVP|NP|VP < CC': 0, 'NP !> NP [<< JJ|POS|PP|S|VBG | << (NP $++ NP !$+ CC)]': 0, 'SBAR [<# WHNP | <# (IN < That|that|For|for) | <, S] & [$+ VP | > VP]': 0, 'MD|VBZ|VBP|VBD > (SQ !< VP)': 0, 'ROOT': 1.0}\n",
      "NP !> NP [<< JJ|POS|PP|S|VBG | << (NP $++ NP !$+ CC)]\n",
      "{'S < (VP <# VBG|TO) $+ VP': 0, 'S|SBARQ|SINV|SQ [> ROOT | [$-- S|SBARQ|SINV|SQ !>> SBAR|VP]] << (SBAR < (S|SINV|SQ [> ROOT <, (VP <# VB) | <# MD|VBZ|VBP|VBD | < (VP [<# MD|VBP|VBZ|VBD | < CC < (VP <# MD|VBP|VBZ|VBD)])]))': 0, 'SBAR < (S|SINV|SQ [> ROOT <, (VP <# VB) | <# MD|VBZ|VBP|VBD | < (VP [<# MD|VBP|VBZ|VBD | < CC < (VP <# MD|VBP|VBZ|VBD)])])': 0, 'VP > S|SINV|SQ': 1.0, 'ADJP|ADVP|NP|VP < CC': 0, 'NP !> NP [<< JJ|POS|PP|S|VBG | << (NP $++ NP !$+ CC)]': 1.0, 'SBAR [<# WHNP | <# (IN < That|that|For|for) | <, S] & [$+ VP | > VP]': 0, 'MD|VBZ|VBP|VBD > (SQ !< VP)': 0, 'ROOT': 1.0}\n",
      "MLC:10.0\n",
      "C/S:1.0\n",
      "CP/C:0.0\n",
      "C/T:1.0\n",
      "DC/C:0.0\n",
      "T/S:1.0\n",
      "DC/T:0.0\n",
      "MLT:10.0\n",
      "CN/C:1.0\n",
      "CT/T:0.0\n",
      "VP/T:1.0\n",
      "CP/T:0.0\n",
      "CN/T:1.0\n"
     ]
    }
   ],
   "source": [
    "#find a random example and compute the non-normalized measures\n",
    "iterator = corpus.iter_utterances()\n",
    "\n",
    "for i in range(randrange(1000)):\n",
    "    s = iterator.next()\n",
    "\n",
    "for tree in s.trees:\n",
    "    print tree\n",
    "    print 'Length: {}'.format(complexity.length(tree))\n",
    "    print 'Depth: {}'.format(complexity.depth(tree))\n",
    "    print 'Width: {}'.format(complexity.width(tree))\n",
    "    #print 'Depth*width: {}'.format(complexity.balanced(tree))\n",
    "    #print 'Balanced depth*width: {}'.format(complexity.balanced2(tree))\n",
    "    #print 'Average depth: {}'.format(complexity.avdepth(tree))\n",
    "print \"Lu's measures:\"\n",
    "for item in complexity.lus_measures(s.trees).items():\n",
    "    print'{}:{}'.format(*item)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the normalized measures for the random example\n",
    "for tree in s.trees:\n",
    "    print 'Normalized depth: {}'.format(complexity.ndepth(tree))\n",
    "    print 'Normalized width: {}'.format(complexity.nwidth(tree))\n",
    "    print 'Normalized depth*width: {}'.format(complexity.nbalanced(tree))\n",
    "    print 'Normalized balanced depth*width: {}'.format(complexity.nbalanced2(tree))\n",
    "    print 'Normalized average depth: {}'.format(complexity.n_avdepth(tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dicts with the measures for easy iteration\n",
    "# add additional measures here\n",
    "measures = {'length': complexity.length,\n",
    "            'depth': complexity.depth,\n",
    "            'width': complexity.width,\n",
    "            'depth*width': complexity.balanced,\n",
    "            'balanced depth*width': complexity.balanced2,\n",
    "            'average depth': complexity.avdepth,\n",
    "            'normalized depth': complexity.ndepth,\n",
    "            'normalized width': complexity.nwidth,\n",
    "            'normalized depth*width': complexity.nbalanced,\n",
    "            'normalized average depth': complexity.n_avdepth,\n",
    "            'normalized balanced depth*width': complexity.nbalanced2}\n",
    "\n",
    "non_normalized_measures = {'length': complexity.length,\n",
    "                           'depth': complexity.depth,\n",
    "                           'width': complexity.width,\n",
    "                           'depth*width': complexity.balanced,\n",
    "                           'balanced depth*width': complexity.balanced2}\n",
    "\n",
    "normalized_measures = {'normalized depth': complexity.ndepth,\n",
    "                       'normalized width': complexity.nwidth,\n",
    "                       'normalized depth*width': complexity.nbalanced,\n",
    "                       'normalized average depth': complexity.n_avdepth,\n",
    "                       'normalized balanced depth*width': complexity.nbalanced2}\n",
    "\n",
    "# dict of sets (to avoid duplicates) for the results\n",
    "ordered_results = dict([(measure, []) for measure in measures])\n",
    "\n",
    "for conv in corpus.iter_transcripts(display_progress=False):\n",
    "    for utt in conv.utterances:\n",
    "        for tree in utt.trees:\n",
    "            #Trees need to be cast to string to be hashable for duplicate removal\n",
    "            string = str(tree)\n",
    "            for measure in measures:\n",
    "                ordered_results[measure].append((conv.conversation_no, measures[measure](tree), string))\n",
    "\n",
    "results = {}\n",
    "#remove duplicates from results            \n",
    "for measure in ordered_results:\n",
    "    results[measure] = list(set(ordered_results[measure]))\n",
    "    results[measure].sort(key=lambda x: x[1])\n",
    "\n",
    "#compute results closest to average\n",
    "av_results = {}\n",
    "\n",
    "for measure in non_normalized_measures:\n",
    "    mean = np.mean([x[1] for x in results[measure]])\n",
    "    av_results[measure] = sorted(results[measure], key=lambda x: abs(x[1] - mean), reverse=True)\n",
    "for measure in normalized_measures:\n",
    "    av_results[measure] = sorted(results[measure], key=lambda x: abs(x[1] - 1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to display top, bot and closest to average n trees per measure\n",
    "\n",
    "n = 5 #length of lists to be displayed\n",
    "\n",
    "# modifiers with associated functions\n",
    "mods = {'Most': lambda x: x[len(x)-n:], 'Least': lambda x: x[:n]}\n",
    "\n",
    "for measure in measures:\n",
    "    for modifier in mods:\n",
    "        print '{} complex trees by {}:\\n'.format(modifier, measure)\n",
    "        for i, item in enumerate(mods[modifier](results[measure]), 1):\n",
    "            tree = Tree.fromstring(item[2])\n",
    "            text = str(tree.flatten()).replace('\\n', '')\n",
    "            print '{}.(from conv. no. {}) {} \\n {}\\n'.format(i, item[0], text, tree)\n",
    "        print '\\n'\n",
    "\n",
    "for measure in av_results:\n",
    "    print 'Closest to average trees by {}\\n'.format(measure)\n",
    "    for i, item in enumerate(mods['Most'](av_results[measure]), 1):\n",
    "        tree = Tree.fromstring(item[2])\n",
    "        text = str(tree.flatten()).replace('\\n', '')\n",
    "        print '{}.(from conv. no. {}) {} \\n {}\\n'.format(i, item[0], text, tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for measure in results:\n",
    "    print len(results[measure])\n",
    "    \n",
    "for i, item in enumerate(ordered_results['normalized depth']):\n",
    "    assert item[2] == ordered_results['normalized average depth'][i][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to find distinguishing sentences for each (sensible) pair of normalized measures\n",
    "\n",
    "i = 0\n",
    "measure_list = list(normalized_measures)\n",
    "diff = {}\n",
    "\n",
    "while i < len(measure_list):\n",
    "    one = measure_list[i]\n",
    "    data_one = [x[1] for x in ordered_results[one]]\n",
    "    for other in measure_list[i + 1:]:\n",
    "        data_other = [x[1] for x in ordered_results[other]]\n",
    "        comp = zip(data_one, data_other)\n",
    "        index, values = max(enumerate(comp), key=lambda x: abs(x[1][0] - x[1][1]))\n",
    "        # sanity check: Are these actually values for the same tree?\n",
    "        #               Do they actually have these values?\n",
    "        assert ordered_results[one][index][2] == ordered_results[other][index][2]\n",
    "        assert ordered_results[one][index][1] == values[0]\n",
    "        assert ordered_results[other][index][1] == values[1]\n",
    "        tree = ordered_results[one][index][2]\n",
    "        diff[(one, other)] = (tree, values)\n",
    "    i += 1\n",
    "    \n",
    "for pair in diff:\n",
    "    print 'Largest difference in value between {} and {}:'.format(*pair)\n",
    "    tree, values = diff[pair]\n",
    "    print 'Value for {pair[0]}: {values[0]}, value for {pair[1]}: {values[1]}'.format(pair=pair, values=values)\n",
    "    print Tree.fromstring(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
